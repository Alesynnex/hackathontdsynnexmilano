{"metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.11", "language": "python"}, "language_info": {"name": "python", "version": "3.11.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "# ==== INSTALLAZIONE (solo se non hai gi\u00e0 i pacchetti) ====\n!pip install -q ibm_watson ibm_cloud_sdk_core ibm_watson_machine_learning gradio pandas openpyxl\n\n# ==== IMPORTS ====\nfrom ibm_watson import DiscoveryV2\nfrom ibm_watson.discovery_v2 import QueryLargePassages\nfrom ibm_cloud_sdk_core.authenticators import IAMAuthenticator\nfrom ibm_cloud_sdk_core import IAMTokenManager\nfrom ibm_watson_machine_learning.foundation_models import Model\nimport json\nimport gradio as gr\nimport pandas as pd\nfrom datetime import datetime\nimport os\n\n# ==== CONFIGURAZIONE ====\ndiscovery_project_id = \"c1aeb15b-e664-4004-b93b-a3947513c9a1\"\nwatsonx_project_id = \"faa54735-bb10-485d-b252-7464d22c729f\"\napi_key = \"u4qcYmojPps_P5KxKQNhpdO5KVqsPTUu-boJfljo5qFl\"  # Discovery\ncloud_account_api_key = 'XE5qCeWjlNNKZwzeB_wQ0JPFo_Yih9cudgk1JaklrdE7'  # Watsonx\n\nservice_url = \"https://api.eu-de.discovery.watson.cloud.ibm.com/instances/ddfd011b-142f-4ea4-8836-f503c73969bf\"\nendpoint = \"https://eu-de.ml.cloud.ibm.com\"\n\n# ==== AUTENTICAZIONE ====\nauthenticator = IAMAuthenticator(api_key)\ndiscovery = DiscoveryV2(version='2020-08-30', authenticator=authenticator)\ndiscovery.set_service_url(service_url)\n\n# Access token per Watsonx\ntry:\n    access_token = IAMTokenManager(\n        apikey=cloud_account_api_key,\n        url=\"https://iam.cloud.ibm.com/identity/token\"\n    ).get_token()\nexcept Exception as e:\n    print(\"Errore autenticazione:\", e)\n\n# ==== MODELLO Watsonx.ai ====\ncredentials = {\n    \"url\": endpoint,\n    \"token\": access_token\n}\n\ngen_params = {\n    \"DECODING_METHOD\": \"sample\",\n    \"MAX_NEW_TOKENS\": 500,\n    \"MIN_NEW_TOKENS\": 2,\n    \"STREAM\": False,\n    \"TEMPERATURE\": 0.3,\n    \"TOP_K\": 50,\n    \"TOP_P\": 1,\n    \"RANDOM_SEED\": 10\n}\n\nmodel_id = \"ibm/granite-3-8b-instruct\"\nmodel = Model(model_id, credentials, gen_params, watsonx_project_id)\n\n# ==== TEMPLATE PROMPT ====\nprompt_template = \"\"\"\nDocumento:\n###\n%s\n###\n\nRispondi alla seguente domanda utilizzando le informazioni presenti in tutti i documenti.\nRispondi con frasi complete, utilizzando lettere maiuscole dove necessario e la punteggiatura corretta.\nCerca attentamente nei file la risposta.\nNon inserire nella risposta altre domande o spiegazioni successive dopo aver risposto alla prima domanda.\nSe non trovi la risposta corretta nel documento, rispondi \"Non lo so\".\n\nDomanda: %s\nRisposta: \n\"\"\"\n\n# ==== FUNZIONI BASE ====\ncombined_disc_results = []\n\ndef query_discovery(question):\n    passages = {\n        \"enabled\": True,\n        \"per_document\": True,\n        \"find_answers\": True,\n        \"max_per_document\": 1,\n        \"characters\": 500\n    }\n\n    query_large_passages_model = QueryLargePassages.from_dict(passages)\n\n    return discovery.query(\n        project_id=discovery_project_id,\n        natural_language_query=question,\n        passages=query_large_passages_model,\n        count=1\n    ).get_result()\n\ndef augment(template_in, context_in, query_in):\n    return template_in % (context_in, query_in)\n\ndef generate(model_in, augmented_prompt_in):\n    generated_response = model_in.generate(augmented_prompt_in)\n\n    if (\"results\" in generated_response\n        and len(generated_response[\"results\"]) > 0\n        and \"generated_text\" in generated_response[\"results\"][0]):\n        return generated_response[\"results\"][0][\"generated_text\"]\n    else:\n        return \"Errore: risposta non generata correttamente.\"\n\n# ==== SENTIMENT MANUALE ====\n# Definizione di parole positive e negative\npositive_words = [\"buono\",\"buona\", \"bene\", \"fantastico\", \"fantasticamente\" \"eccellente\", \"ottimo\", \"positivo\", \"positiva\" \"bellissimo\", \"bellissima\", \"ottima\", \"stupendo\", \"stupenda\"]\nnegative_words = [\"negativo\", \"pessimo\", \"pessima\" \"terribile\", \"brutta\", \"brutto\", \"malissimo\", \"scadente\", \"deludente\", \"delusione\", \"orribile\"]\n\n# Funzione per analizzare il sentiment manualmente\ndef manual_sentiment(feedback):\n    feedback = feedback.lower()\n    positive_count = sum(1 for word in positive_words if word in feedback)\n    negative_count = sum(1 for word in negative_words if word in feedback)\n\n    if positive_count > negative_count:\n        return \"POSITIVE\"\n    elif negative_count > positive_count:\n        return \"NEGATIVE\"\n    else:\n        return \"NEUTRAL\"\n\n# Funzione per processare il feedback e gestire il sentiment manuale\ndef process_feedback(feedback, question, risposta):\n    try:\n        # Analisi del sentiment manuale\n        sentiment = manual_sentiment(feedback)\n\n        # 3. Salvataggio su Excel\n        data = {\n            \"Timestamp\": [datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")],\n            \"Feedback\": [feedback],\n            \"Sentiment\": [sentiment]\n        }\n\n        df_new = pd.DataFrame(data)\n        file_path = \"feedback_watson.xlsx\"\n\n        if os.path.exists(file_path):\n            df_existing = pd.read_excel(file_path)\n            df_combined = pd.concat([df_existing, df_new], ignore_index=True)\n        else:\n            df_combined = df_new\n\n        df_combined.to_excel(file_path, index=False)\n\n        return f\"Feedback ricevuto e salvato con successo. Sentiment: {sentiment}\", file_path\n\n    except Exception as e:\n        return f\"Errore durante l'elaborazione del feedback: {str(e)}\", None\n\n\n# ==== FUNZIONE PRINCIPALE PER LA RICEZIONE DELLA DOMANDA E DEL FEEDBACK ====\ndef chat_watson_fase1(question):\n    try:\n        # 1. Risposta Watson\n        discovery_json = query_discovery(question)\n        combined_disc_results.clear()\n\n        for doc_index in range(len(discovery_json[\"results\"])):\n            for j in range(len(discovery_json[\"results\"][doc_index])):\n                passages = discovery_json[\"results\"][doc_index][\"document_passages\"]\n                disc_results = []\n                for item in passages:\n                    item = item[\"passage_text\"].replace(\"<em>\", \"\").replace(\"</em>\", \"\")\n                    disc_results.append(item)\n                combined_disc_results.append(\"\\n\".join(disc_results))\n\n        augmented_prompt = augment(prompt_template, combined_disc_results, question)\n        risposta = generate(model, augmented_prompt)\n\n        return risposta\n\n    except Exception as e:\n        return f\"Errore durante l'elaborazione della domanda: {str(e)}\"\n\n\n# ==== INTERFACCIA GRADIO DIVISA IN DUE FASI ====\ndef fase1_ui(question):\n    risposta = chat_watson_fase1(question)\n    return risposta\n\ndef fase2_ui(feedback, question, risposta):\n    return process_feedback(feedback, question, risposta)\n\n\n# Gradio per la **fase 1** (domanda e risposta)\niface1 = gr.Interface(\n    fn=fase1_ui,\n    inputs=gr.Textbox(lines=3, label=\"Fai una domanda\"),\n    outputs=gr.Textbox(lines=10, label=\"Risposta\"),\n    title=\"Fase 1 - Domanda e Risposta\",\n    description=\"Fai una domanda e ricevi una risposta.\"\n)\n\n# Gradio per la **fase 2** (feedback)\niface2 = gr.Interface(\n    fn=fase2_ui,\n    inputs=gr.Textbox(lines=2, label=\"Lascia un feedback (opzionale)\"),\n    outputs=[\n        gr.Textbox(lines=5, label=\"Risultato Feedback\"),\n        gr.File(label=\"Scarica il file Excel con i feedback\")\n    ],\n    title=\"Fase 2 - Feedback e Sentiment\",\n    description=\"Lascia un feedback sulla risposta e vedi il sentiment.\"\n)\n\n# Lancia Fase 1\niface1.launch(share=True)  # Lancia la fase 1\n\n# Una volta che l'utente ha visto la risposta, lancia Fase 2\niface2.launch(share=True)  # Lancia la fase 2\n", "metadata": {"id": "47491e5e-de7b-45ab-a8e3-14e00cb627c5"}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": "", "metadata": {"id": "469eef69-2ac2-4113-98f6-3334616a2755"}, "outputs": [], "execution_count": null}]}